{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZCUbglGCU8dcuKhVooyqu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GAYATHRI24042003/ML/blob/main/Iris_Dataset_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdPFh80rZgdI",
        "outputId": "76ca6e71-4f33-4bac-b4df-9d50cad52c56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Test Loss: 3.7527, Accuracy: 50.00%\n",
            "Epoch 2/100, Test Loss: 1.8145, Accuracy: 56.67%\n",
            "Epoch 3/100, Test Loss: 0.9222, Accuracy: 63.33%\n",
            "Epoch 4/100, Test Loss: 0.6333, Accuracy: 80.00%\n",
            "Epoch 5/100, Test Loss: 0.3757, Accuracy: 90.00%\n",
            "Epoch 6/100, Test Loss: 0.2689, Accuracy: 90.00%\n",
            "Epoch 7/100, Test Loss: 0.2015, Accuracy: 90.00%\n",
            "Epoch 8/100, Test Loss: 0.1725, Accuracy: 93.33%\n",
            "Epoch 9/100, Test Loss: 0.1959, Accuracy: 93.33%\n",
            "Epoch 10/100, Test Loss: 0.2067, Accuracy: 96.67%\n",
            "Epoch 11/100, Test Loss: 0.2140, Accuracy: 96.67%\n",
            "Epoch 12/100, Test Loss: 0.2174, Accuracy: 96.67%\n",
            "Epoch 13/100, Test Loss: 0.2091, Accuracy: 96.67%\n",
            "Epoch 14/100, Test Loss: 0.1923, Accuracy: 96.67%\n",
            "Epoch 15/100, Test Loss: 0.1774, Accuracy: 96.67%\n",
            "Epoch 16/100, Test Loss: 0.1667, Accuracy: 96.67%\n",
            "Epoch 17/100, Test Loss: 0.1561, Accuracy: 96.67%\n",
            "Epoch 18/100, Test Loss: 0.1422, Accuracy: 96.67%\n",
            "Epoch 19/100, Test Loss: 0.1276, Accuracy: 96.67%\n",
            "Epoch 20/100, Test Loss: 0.1161, Accuracy: 96.67%\n",
            "Epoch 21/100, Test Loss: 0.1085, Accuracy: 96.67%\n",
            "Epoch 22/100, Test Loss: 0.1033, Accuracy: 96.67%\n",
            "Epoch 23/100, Test Loss: 0.0998, Accuracy: 96.67%\n",
            "Epoch 24/100, Test Loss: 0.0980, Accuracy: 96.67%\n",
            "Epoch 25/100, Test Loss: 0.0977, Accuracy: 96.67%\n",
            "Epoch 26/100, Test Loss: 0.0978, Accuracy: 96.67%\n",
            "Epoch 27/100, Test Loss: 0.0973, Accuracy: 96.67%\n",
            "Epoch 28/100, Test Loss: 0.0962, Accuracy: 96.67%\n",
            "Epoch 29/100, Test Loss: 0.0949, Accuracy: 96.67%\n",
            "Epoch 30/100, Test Loss: 0.0936, Accuracy: 96.67%\n",
            "Epoch 31/100, Test Loss: 0.0923, Accuracy: 96.67%\n",
            "Epoch 32/100, Test Loss: 0.0906, Accuracy: 96.67%\n",
            "Epoch 33/100, Test Loss: 0.0888, Accuracy: 96.67%\n",
            "Epoch 34/100, Test Loss: 0.0869, Accuracy: 96.67%\n",
            "Epoch 35/100, Test Loss: 0.0850, Accuracy: 96.67%\n",
            "Epoch 36/100, Test Loss: 0.0832, Accuracy: 96.67%\n",
            "Epoch 37/100, Test Loss: 0.0814, Accuracy: 96.67%\n",
            "Epoch 38/100, Test Loss: 0.0796, Accuracy: 96.67%\n",
            "Epoch 39/100, Test Loss: 0.0781, Accuracy: 96.67%\n",
            "Epoch 40/100, Test Loss: 0.0765, Accuracy: 96.67%\n",
            "Epoch 41/100, Test Loss: 0.0750, Accuracy: 96.67%\n",
            "Epoch 42/100, Test Loss: 0.0735, Accuracy: 96.67%\n",
            "Epoch 43/100, Test Loss: 0.0723, Accuracy: 96.67%\n",
            "Epoch 44/100, Test Loss: 0.0712, Accuracy: 96.67%\n",
            "Epoch 45/100, Test Loss: 0.0701, Accuracy: 96.67%\n",
            "Epoch 46/100, Test Loss: 0.0686, Accuracy: 96.67%\n",
            "Epoch 47/100, Test Loss: 0.0671, Accuracy: 96.67%\n",
            "Epoch 48/100, Test Loss: 0.0658, Accuracy: 96.67%\n",
            "Epoch 49/100, Test Loss: 0.0652, Accuracy: 96.67%\n",
            "Epoch 50/100, Test Loss: 0.0647, Accuracy: 96.67%\n",
            "Epoch 51/100, Test Loss: 0.0638, Accuracy: 96.67%\n",
            "Epoch 52/100, Test Loss: 0.0622, Accuracy: 96.67%\n",
            "Epoch 53/100, Test Loss: 0.0606, Accuracy: 96.67%\n",
            "Epoch 54/100, Test Loss: 0.0598, Accuracy: 96.67%\n",
            "Epoch 55/100, Test Loss: 0.0596, Accuracy: 96.67%\n",
            "Epoch 56/100, Test Loss: 0.0590, Accuracy: 96.67%\n",
            "Epoch 57/100, Test Loss: 0.0578, Accuracy: 96.67%\n",
            "Epoch 58/100, Test Loss: 0.0565, Accuracy: 96.67%\n",
            "Epoch 59/100, Test Loss: 0.0559, Accuracy: 96.67%\n",
            "Epoch 60/100, Test Loss: 0.0560, Accuracy: 96.67%\n",
            "Epoch 61/100, Test Loss: 0.0555, Accuracy: 96.67%\n",
            "Epoch 62/100, Test Loss: 0.0544, Accuracy: 96.67%\n",
            "Epoch 63/100, Test Loss: 0.0535, Accuracy: 96.67%\n",
            "Epoch 64/100, Test Loss: 0.0529, Accuracy: 96.67%\n",
            "Epoch 65/100, Test Loss: 0.0523, Accuracy: 96.67%\n",
            "Epoch 66/100, Test Loss: 0.0515, Accuracy: 96.67%\n",
            "Epoch 67/100, Test Loss: 0.0503, Accuracy: 96.67%\n",
            "Epoch 68/100, Test Loss: 0.0495, Accuracy: 96.67%\n",
            "Epoch 69/100, Test Loss: 0.0488, Accuracy: 96.67%\n",
            "Epoch 70/100, Test Loss: 0.0482, Accuracy: 96.67%\n",
            "Epoch 71/100, Test Loss: 0.0478, Accuracy: 96.67%\n",
            "Epoch 72/100, Test Loss: 0.0473, Accuracy: 96.67%\n",
            "Epoch 73/100, Test Loss: 0.0465, Accuracy: 96.67%\n",
            "Epoch 74/100, Test Loss: 0.0456, Accuracy: 96.67%\n",
            "Epoch 75/100, Test Loss: 0.0444, Accuracy: 96.67%\n",
            "Epoch 76/100, Test Loss: 0.0433, Accuracy: 96.67%\n",
            "Epoch 77/100, Test Loss: 0.0431, Accuracy: 96.67%\n",
            "Epoch 78/100, Test Loss: 0.0431, Accuracy: 96.67%\n",
            "Epoch 79/100, Test Loss: 0.0426, Accuracy: 96.67%\n",
            "Epoch 80/100, Test Loss: 0.0417, Accuracy: 96.67%\n",
            "Epoch 81/100, Test Loss: 0.0409, Accuracy: 96.67%\n",
            "Epoch 82/100, Test Loss: 0.0406, Accuracy: 96.67%\n",
            "Epoch 83/100, Test Loss: 0.0403, Accuracy: 96.67%\n",
            "Epoch 84/100, Test Loss: 0.0403, Accuracy: 96.67%\n",
            "Epoch 85/100, Test Loss: 0.0402, Accuracy: 96.67%\n",
            "Epoch 86/100, Test Loss: 0.0395, Accuracy: 96.67%\n",
            "Epoch 87/100, Test Loss: 0.0384, Accuracy: 96.67%\n",
            "Epoch 88/100, Test Loss: 0.0377, Accuracy: 96.67%\n",
            "Epoch 89/100, Test Loss: 0.0374, Accuracy: 96.67%\n",
            "Epoch 90/100, Test Loss: 0.0369, Accuracy: 96.67%\n",
            "Epoch 91/100, Test Loss: 0.0362, Accuracy: 96.67%\n",
            "Epoch 92/100, Test Loss: 0.0355, Accuracy: 96.67%\n",
            "Epoch 93/100, Test Loss: 0.0351, Accuracy: 96.67%\n",
            "Epoch 94/100, Test Loss: 0.0346, Accuracy: 100.00%\n",
            "Epoch 95/100, Test Loss: 0.0339, Accuracy: 100.00%\n",
            "Epoch 96/100, Test Loss: 0.0339, Accuracy: 100.00%\n",
            "Epoch 97/100, Test Loss: 0.0338, Accuracy: 100.00%\n",
            "Epoch 98/100, Test Loss: 0.0332, Accuracy: 100.00%\n",
            "Epoch 99/100, Test Loss: 0.0328, Accuracy: 100.00%\n",
            "Epoch 100/100, Test Loss: 0.0328, Accuracy: 100.00%\n",
            "Final Test Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data (normalize features to have mean=0 and variance=1)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train_one_hot = tf.one_hot(y_train, depth=3)\n",
        "y_test_one_hot = tf.one_hot(y_test, depth=3)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "hidden_size = 64\n",
        "\n",
        "# Neural network architecture\n",
        "input_size = X_train_scaled.shape[1]\n",
        "output_size = 3  # Number of classes in Iris dataset\n",
        "\n",
        "# Initialize weights and biases for the first layer\n",
        "W1 = tf.Variable(tf.random.normal([input_size, hidden_size], dtype=tf.float32), name='weights1')\n",
        "b1 = tf.Variable(tf.zeros([hidden_size], dtype=tf.float32), name='biases1')\n",
        "\n",
        "# Initialize weights and biases for the second layer\n",
        "W2 = tf.Variable(tf.random.normal([hidden_size, output_size], dtype=tf.float32), name='weights2')\n",
        "b2 = tf.Variable(tf.zeros([output_size], dtype=tf.float32), name='biases2')\n",
        "\n",
        "# Define the neural network model\n",
        "def neural_network(x):\n",
        "    # First hidden layer\n",
        "    hidden_layer = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
        "\n",
        "    # Output layer\n",
        "    output_layer = tf.nn.softmax(tf.matmul(hidden_layer, W2) + b2)\n",
        "\n",
        "    return output_layer\n",
        "\n",
        "# Loss function (cross-entropy)\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred), axis=1))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.optimizers.Adam(learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    for i in range(0, len(X_train_scaled), batch_size):\n",
        "        x_batch = tf.constant(X_train_scaled[i:i+batch_size], dtype=tf.float32)\n",
        "        y_batch = tf.constant(y_train_one_hot[i:i+batch_size], dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = neural_network(x_batch)\n",
        "            loss = cross_entropy_loss(y_batch, predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, [W1, b1, W2, b2])\n",
        "        optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))\n",
        "\n",
        "    # Evaluate the model on the test set after each epoch\n",
        "    test_predictions = neural_network(tf.constant(X_test_scaled, dtype=tf.float32))\n",
        "    test_loss = cross_entropy_loss(y_test_one_hot, test_predictions)\n",
        "    accuracy = accuracy_score(y_test, tf.argmax(test_predictions, axis=1).numpy())\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Test the final model on the test set\n",
        "final_test_predictions = neural_network(tf.constant(X_test_scaled, dtype=tf.float32))\n",
        "final_accuracy = accuracy_score(y_test, tf.argmax(final_test_predictions, axis=1).numpy())\n",
        "print(f\"Final Test Accuracy: {final_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GC-caYO2b3qW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}